---
---

@article{2210.06516v2,
  author        = {Yi Zeng and Minzhou Pan and Himanshu Jahagirdar and Ming Jin and Lingjuan Lyu and Ruoxi Jia},
  title         = {How to Sift Out a Clean Data Subset in the Presence of Data Poisoning?},
  eprint        = {2210.06516v2},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  abstract      = {External data sources are increasingly being used to train
                  machine learning (ML) models as the data demand increases.
                  However, the integration of external data into training poses
                  data poisoning risks, where malicious providers manipulate
                  their data to compromise the utility or integrity of the model.
                  Most data poisoning defenses assume access to a set of clean
                  data (referred to as the base set), which could be obtained
                  through trusted sources. But it also becomes common that
                  entire data sources for an ML task are untrusted (e.g., Internet
                  data). In this case, one needs to identify a subset within a
                  contaminated dataset as the base set to support these defenses.
                  This paper starts by examining the performance of defenses
                  when poisoned samples are mistakenly mixed into the base
                  set. We analyze five representative defenses that use base sets
                  and find that their performance deteriorates dramatically with
                  less than 1% poisoned points in the base set. These findings
                  suggest that sifting out a base set with high precision is key to
                  these defenses' performance. Motivated by these observations,
                  we study how precise existing automated tools and human
                  inspection are at identifying clean data in the presence of data
                  poisoning. Unfortunately, neither effort achieves the precision
                  needed that enables effective defenses. Worse yet, many of the
                  outcomes of these methods are worse than random selection.
                  In addition to uncovering the challenge, we take a step further and propose a practical countermeasure, META-SIFT .
                  Our method is based on the insight that existing poisoning attacks shift data distributions, resulting in high prediction loss
                  when training on the clean portion of a poisoned dataset and
                  testing on the corrupted portion. Leveraging the insight, we
                  formulate a bilevel optimization to identify clean data and further introduce a suite of techniques to improve the efficiency
                  and precision of the identification. Our evaluation shows that
                  META-SIFT can sift a clean base set with 100% precision
                  under a wide range of poisoning threats. The selected base
                  set is large enough to give rise to successful defense when
                  plugged into the existing defense techniques.},
  year          = {2023},
  month         = {May},
  url           = {https://arxiv.org/abs/2210.06516v2},
  file          = {2210.06516v2.pdf},
  eprintnover   = {2210.06516}
}

@article{1602.05629,
  author        = {H. Brendan McMahan and Eider Moore and Daniel Ramage and Seth Hampson and Blaise Agüera y Arcas},
  title         = {Communication-Efficient Learning of Deep Networks from Decentralized Data},
  eprint        = {1602.05629},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  abstract      = {Modern mobile devices have access to a wealth
                  of data suitable for learning models, which in turn
                  can greatly improve the user experience on the
                  device. For example, language models can improve speech recognition and text entry, and image models can automatically select good photos.
                  However, this rich data is often privacy sensitive,
                  large in quantity, or both, which may preclude
                  logging to the data center and training there using
                  conventional approaches. We advocate an alternative that leaves the training data distributed on
                  the mobile devices, and learns a shared model by
                  aggregating locally-computed updates. We term
                  this decentralized approach Federated Learning.
                  We present a practical method for the federated
                  learning of deep networks based on iterative
                  model averaging, and conduct an extensive empirical evaluation, considering five different model architectures and four datasets. These experiments
                  demonstrate the approach is robust to the unbalanced and non-IID data distributions that are a
                  defining characteristic of this setting. Communication costs are the principal constraint, and
                  we show a reduction in required communication
                  rounds by 10-100x as compared to synchronized
                  stochastic gradient descent.},
  year          = {2016},
  month         = {Feb},
  url           = {https://arxiv.org/abs/1602.05629},
  file          = {1602.05629.pdf},
  eprintnover   = {1602.05629}
}

@article{1708.06733,
  author        = {Tianyu Gu and Brendan Dolan-Gavitt and Siddharth Garg},
  title         = {BadNets: Identifying Vulnerabilities in the Machine Learning Model Supply Chain},
  eprint        = {1708.06733},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  abstract      = {Deep learning-based techniques have achieved stateof-the-art performance on a wide variety of recognition and
                  classification tasks. However, these networks are typically computationally expensive to train, requiring weeks of computation
                  on many GPUs; as a result, many users outsource the training
                  procedure to the cloud or rely on pre-trained models that
                  are then fine-tuned for a specific task. In this paper we
                  show that outsourced training introduces new security risks:
                  an adversary can create a maliciously trained network (a
                  backdoored neural network, or a BadNet) that has state-of-theart performance on the user's training and validation samples,
                  but behaves badly on specific attacker-chosen inputs. We first
                  explore the properties of BadNets in a toy example, by creating
                  a backdoored handwritten digit classifier. Next, we demonstrate
                  backdoors in a more realistic scenario by creating a U.S. street
                  sign classifier that identifies stop signs as speed limits when
                  a special sticker is added to the stop sign; we then show in
                  addition that the backdoor in our US street sign detector can
                  persist even if the network is later retrained for another task
                  and cause a drop in accuracy of 25% on average when the
                  backdoor trigger is present. These results demonstrate that
                  backdoors in neural networks are both powerful and—because
                  the behavior of neural networks is difficult to explicate—
                  stealthy. This work provides motivation for further research
                  into techniques for verifying and inspecting neural networks,
                  just as we have developed tools for verifying and debugging
                  software.},
  year          = {2017},
  month         = {Aug},
  url           = {https://arxiv.org/abs/1708.06733},
  file          = {1708.06733.pdf},
  eprintnover   = {1708.06733}
}

@article{1512.03385,
  author        = {Kaiming He and Xiangyu Zhang and Shaoqing Ren and Jian Sun},
  title         = {Deep Residual Learning for Image Recognition},
  eprint        = {1512.03385},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  abstract      = {Deeper neural networks are more difficult to train. We
                  present a residual learning framework to ease the training
                  of networks that are substantially deeper than those used
                  previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual
                  networks are easier to optimize, and can gain accuracy from
                  considerably increased depth. On the ImageNet dataset we
                  evaluate residual nets with a depth of up to 152 layers—8x
                  deeper than VGG nets [41] but still having lower complexity. An ensemble of these residual nets achieves 3.57% error
                  on the ImageNet test set. This result won the 1st place on the
                  ILSVRC 2015 classification task. We also present analysis
                  on CIFAR-10 with 100 and 1000 layers.
                  The depth of representations is of central importance
                  for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28% relative improvement on the COCO object detection dataset. Deep
                  residual nets are foundations of our submissions to ILSVRC
                  & COCO 2015 competitions1
                  , where we also won the 1st
                  places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation.},
  year          = {2015},
  month         = {Dec},
  url           = {https://arxiv.org/abs/1512.03385},
  file          = {1512.03385.pdf},
  eprintnover   = {1512.03385}
}

@article{1706.03762,
  author        = {Ashish Vaswani Noam Shazeer Niki Parmar Jakob Uszkoreit Llion Jones Aidan N. Gomez Lukasz Kaiser Illia Polosukhin},
  title         = {Attention Is All You Need},
  eprint        = {1706.03762},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  abstract      = {The dominant sequence transduction models are based on complex recurrent or
                  convolutional neural networks that include an encoder and a decoder. The best
                  performing models also connect the encoder and decoder through an attention
                  mechanism. We propose a new simple network architecture, the Transformer,
                  based solely on attention mechanisms, dispensing with recurrence and convolutions
                  entirely. Experiments on two machine translation tasks show these models to
                  be superior in quality while being more parallelizable and requiring significantly
                  less time to train. Our model achieves 28.4 BLEU on the WMT 2014 Englishto-German translation task, improving over the existing best results, including
                  ensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task,
                  our model establishes a new single-model state-of-the-art BLEU score of 41.8 after
                  training for 3.5 days on eight GPUs, a small fraction of the training costs of the
                  best models from the literature. We show that the Transformer generalizes well to
                  other tasks by applying it successfully to English constituency parsing both with
                  large and limited training data.},
  year          = {2017},
  month         = {Jun},
  url           = {https://arxiv.org/abs/1706.03762},
  file          = {1706.03762.pdf},
  eprintnover   = {1706.03762}
}

@article{2305.19229,
  author        = {Rui Ye and Mingkai Xu and Jianyu Wang and Chenxin Xu and Siheng Chen and Yanfeng Wang},
  title         = {FedDisco: Federated Learning with Discrepancy-Aware Collaboration},
  eprint        = {2305.19229},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  abstract      = {This work considers the category distribution heterogeneity in federated learning. This issue is due
                  to biased labeling preferences at multiple clients
                  and is a typical setting of data heterogeneity. To
                  alleviate this issue, most previous works consider
                  either regularizing local models or fine-tuning the
                  global model, while they ignore the adjustment
                  of aggregation weights and simply assign weights
                  based on the dataset size. However, based on our
                  empirical observations and theoretical analysis,
                  we find that the dataset size is not optimal and
                  the discrepancy between local and global category distributions could be a beneficial and complementary indicator for determining aggregation
                  weights. We thus propose a novel aggregation
                  method, Federated Learning with Discrepancyaware Collaboration (FedDisco), whose aggregation weights not only involve both the dataset
                  size and the discrepancy value, but also contribute
                  to a tighter theoretical upper bound of the optimization error. FedDisco also promotes privacypreservation, communication and computation
                  efficiency, as well as modularity. Extensive experiments show that our FedDisco outperforms
                  several state-of-the-art methods and can be easily incorporated with many existing methods to
                  further enhance the performance.},
  year          = {2023},
  month         = {May},
  url           = {https://arxiv.org/abs/2305.19229},
  file          = {2305.19229.pdf},
  eprintnover   = {2305.19229}
}

@article{1312.5602,
  author        = {Volodymyr Mnih and Koray Kavukcuoglu and David Silver and Alex Graves and Ioannis Antonoglou and Daan Wierstra and Martin Riedmiller},
  title         = {Playing Atari with Deep Reinforcement Learning},
  eprint        = {1312.5602},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  abstract      = {We present the first deep learning model to successfully learn control policies directly from high-dimensional sensory input using reinforcement learning. The
                  model is a convolutional neural network, trained with a variant of Q-learning,
                  whose input is raw pixels and whose output is a value function estimating future
                  rewards. We apply our method to seven Atari 2600 games from the Arcade Learning Environment, with no adjustment of the architecture or learning algorithm. We
                  find that it outperforms all previous approaches on six of the games and surpasses
                  a human expert on three of them.},
  year          = {2013},
  month         = {Dec},
  url           = {https://arxiv.org/abs/1312.5602},
  file          = {1312.5602.pdf},
  eprintnover   = {1312.5602}
}

